# Car Plate Classifier / Clasificador de Matr√≠culas

Proyecto profesional para detecci√≥n de placas vehiculares usando Redes Neuronales Fully Connected con caracter√≠sticas HOG y BRISK.

## üìã Descripci√≥n

Este proyecto implementa m√∫ltiples enfoques para detecci√≥n de placas vehiculares:

### Enfoque Cl√°sico (HOG/BRISK + FC)
- **Caracter√≠sticas HOG** (Histogram of Oriented Gradients)
- **Caracter√≠sticas BRISK** (Binary Robust Invariant Scalable Keypoints)
- **Redes Neuronales Fully Connected** para regresi√≥n de coordenadas

### Enfoque Deep Learning (RetinaNet) ‚ú® **NUEVO**
- **RetinaNet**: Detector end-to-end state-of-the-art
- **ResNet-50 / MobileNetV2**: Backbones pre-entrenados
- **Feature Pyramid Network (FPN)**: Detecci√≥n multi-escala
- **Focal Loss**: Manejo inteligente de class imbalance

## üèóÔ∏è Estructura del Proyecto

```
fc-detection-project/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ features/           # Extracci√≥n de caracter√≠sticas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py        # Interfaz base
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hog.py         # Extractor HOG
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ brisk.py       # Extractor BRISK
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Arquitecturas de redes neuronales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fc_network.py  # Redes Fully Connected
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layers.py      # Capas personalizadas
‚îÇ   ‚îú‚îÄ‚îÄ data/              # Pipeline de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py     # Dataset loaders
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transforms.py  # Augmentaciones
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py       # Utilidades
‚îÇ   ‚îú‚îÄ‚îÄ training/          # Sistema de entrenamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py     # Training loops
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ callbacks.py   # Callbacks personalizados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ losses.py      # Funciones de p√©rdida
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/        # M√©tricas y evaluaci√≥n
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ metrics.py     # IoU, MAE, etc.
‚îÇ       ‚îî‚îÄ‚îÄ visualize.py   # Visualizaci√≥n de resultados
‚îú‚îÄ‚îÄ configs/               # Archivos de configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ hog_config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ brisk_config.yaml
‚îú‚îÄ‚îÄ scripts/               # Scripts de utilidad
‚îÇ   ‚îú‚îÄ‚îÄ prepare_dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îî‚îÄ‚îÄ inference.py
‚îú‚îÄ‚îÄ tests/                 # Tests unitarios
‚îÇ   ‚îú‚îÄ‚îÄ test_features.py
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îî‚îÄ‚îÄ test_data.py
‚îú‚îÄ‚îÄ notebooks/             # Jupyter notebooks
‚îÇ   ‚îî‚îÄ‚îÄ exploratory_analysis.ipynb
‚îú‚îÄ‚îÄ docs/                  # Documentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ api.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Instalaci√≥n

### 1. Clonar el repositorio

```bash
git clone https://github.com/RickContreras/car-plate-classifier.git
cd car-plate-classifier
```

### 2. Crear entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate  # Windows
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Instalar el paquete en modo desarrollo

```bash
pip install -e .
```

## üìä Preparaci√≥n de Datos

## üîë Configuraci√≥n de Kaggle API

Para descargar los datos autom√°ticamente, necesitas configurar tus credenciales de Kaggle:

1. üìù Inicia sesi√≥n en [Kaggle](https://www.kaggle.com/)
2. ‚öôÔ∏è Ve a **Settings** ‚Üí **API** ‚Üí **Create New API Token**
3. üíæ Descarga el archivo `kaggle.json`
4. üìÅ Coloca `kaggle.json` en la **ra√≠z del proyecto**

```bash
coffee-quality-prediction/
‚îú‚îÄ‚îÄ kaggle.json ‚úÖ  # Aqu√≠
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ ...
```

## üíª Uso

### üì• 1. Descargar datos

```bash
python3 scripts/download_data.py
```

> üí° **Nota:** Tambi√©n puedes descargar manualmente desde [Kaggle](https://www.kaggle.com/datasets/andrewmvd/car-plate-detection/data)

### Formato de Dataset

El proyecto espera im√°genes con anotaciones en formato Pascal VOC XML:

```xml
<annotation>
  <filename>image.jpg</filename>
  <object>
    <name>licence</name>
    <bndbox>
      <xmin>100</xmin>
      <ymin>150</ymin>
      <xmax>300</xmax>
      <ymax>250</ymax>
    </bndbox>
  </object>
</annotation>
```

### Preparar Dataset

**Para RetinaNet (Deep Learning):** ‚≠ê No necesitas este paso, el dataset se carga directamente durante el entrenamiento.

**Para modelos cl√°sicos (HOG/BRISK):**

```bash
# Preparar dataset HOG
python3 scripts/prepare_dataset.py \
    --images data/raw/images \
    --annotations data/raw/annotations \
    --feature-type hog \
    --output data/processed/detection_hog.pkl

# Preparar dataset BRISK
python3 scripts/prepare_dataset.py \
    --images data/raw/images \
    --annotations data/raw/annotations \
    --feature-type brisk \
    --output data/processed/detection_brisk.pkl
```

## üéØ Entrenamiento

### Entrenar RetinaNet

```bash
python scripts/train_retinanet.py --config configs/retinanet_config.yaml
```

### Entrenar modelo HOG

```bash
python scripts/train.py --config configs/hog_config.yaml
```

### Entrenar modelo BRISK

```bash
python scripts/train.py --config configs/brisk_config.yaml
```

### Entrenar todos los modelos (comparaci√≥n completa)

```bash
# Modelos cl√°sicos
python scripts/train.py --config configs/hog_config.yaml
python scripts/train.py --config configs/brisk_config.yaml

# RetinaNet
python scripts/train_retinanet.py --config configs/retinanet_config.yaml
```

### Par√°metros personalizados (modelos cl√°sicos)

```bash
python scripts/train.py \
    --feature-type hog \
    --epochs 100 \
    --batch-size 32 \
    --learning-rate 0.001 \
    --patience 15
```

## üìà Evaluaci√≥n

### Evaluar RetinaNet

```bash
python scripts/evaluate_retinanet.py \
    --model models/retinanet_plates.h5 \
    --config configs/retinanet_config.yaml
```

### Evaluar modelos cl√°sicos

```bash
python scripts/evaluate.py \
    --model models/detection_hog.h5 \
    --feature-type hog \
    --data data/processed/test
```

## üîÆ Inferencia

```bash
python scripts/inference.py \
    --model models/detection_hog.h5 \
    --feature-type hog \
    --image path/to/image.jpg \
    --output results/
```

## üìä M√©tricas de Rendimiento

### Comparaci√≥n de Modelos

| Modelo | MAE | IoU Promedio | IoU > 0.5 | Par√°metros | Velocidad |
|--------|-----|--------------|-----------|------------|-----------|
| HOG + FC    | 7.45% | 39.55% | 48.3% | 4.3M | ~10 FPS |
| BRISK + FC  | 6.89% | 17.20% | 10.3% | 439K | ~10 FPS |
| **RetinaNet** | **~4%** | **~65%** | **~85%** | **23M** | **~20 FPS** |

> üí° **Nota:** RetinaNet ofrece significativamente mejor precisi√≥n con un entrenamiento end-to-end

## üîß Configuraci√≥n

### Archivo de configuraci√≥n (YAML)

```yaml
# configs/hog_config.yaml
feature_extractor:
  type: hog
  params:
    orientations: 9
    pixels_per_cell: 8
    cells_per_block: 3

model:
  architecture:
    - units: 512
      activation: relu
      batch_norm: true
      dropout: 0.3
    - units: 256
      activation: relu
      batch_norm: true
      dropout: 0.3
    - units: 128
      activation: relu
      batch_norm: true
      dropout: 0.2
    - units: 64
      activation: relu
      dropout: 0.2
    - units: 4
      activation: sigmoid

training:
  epochs: 100
  batch_size: 32
  learning_rate: 0.001
  optimizer: adam
  loss: mse
  callbacks:
    - type: early_stopping
      patience: 15
      monitor: val_loss
    - type: reduce_lr
      factor: 0.5
      patience: 7
    - type: model_checkpoint
      save_best_only: true
      monitor: val_avg_iou
```

## üß™ Tests

Ejecutar todos los tests:

```bash
pytest tests/ -v
```

Ejecutar tests espec√≠ficos:

```bash
pytest tests/test_features.py -v
pytest tests/test_models.py -v
```

Con cobertura:

```bash
pytest tests/ --cov=src --cov-report=html
```

## üìö API Reference

### RetinaNet (End-to-End)

```python
from src.models.retinanet import RetinaNetDetector
from src.data.retinanet_dataset import RetinaNetDataset

# Crear detector
detector = RetinaNetDetector(
    num_classes=1,
    input_shape=(640, 640, 3),
    backbone_type='resnet50'
)

# Construir y compilar modelo
model = detector.build()
model = detector.compile_model(model, learning_rate=1e-4)

# Cargar dataset
dataset = RetinaNetDataset.from_pascal_voc(
    images_dir='data/raw/images',
    annotations_dir='data/raw/annotations'
)

train_ds, val_ds = dataset.split(train_ratio=0.8)

# Entrenar
history = model.fit(
    train_ds.get_tf_dataset(batch_size=4),
    validation_data=val_ds.get_tf_dataset(batch_size=4),
    epochs=100
)
```

### Feature Extractors (Cl√°sico)

```python
from src.features import HOGFeatureExtractor, BRISKFeatureExtractor

# HOG
hog = HOGFeatureExtractor(orientations=9, pixels_per_cell=8)
features = hog.extract(image)

# BRISK
brisk = BRISKFeatureExtractor(n_keypoints=512)
features = brisk.extract(image)
```

### Models (Cl√°sico)

```python
from src.models import FCNetwork

model = FCNetwork(
    input_dim=8100,
    architecture=[512, 256, 128, 64, 4],
    activations=['relu', 'relu', 'relu', 'relu', 'sigmoid']
)
model.compile(optimizer='adam', loss='mse')
```

### Training (Cl√°sico)

```python
from src.training import Trainer

trainer = Trainer(model, config)
history = trainer.train(train_data, val_data)
```

## üé® Visualizaci√≥n

```python
from src.evaluation import visualize_predictions

visualize_predictions(
    model=model,
    images=test_images,
    ground_truth=test_boxes,
    save_path='results/predictions.png'
)
```

## ü§ù Contribuciones

1. Fork del proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit de cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## üìñ Referencias

### Papers Implementados

**RetinaNet:**
- Lin, T. Y., et al. (2017). "Focal Loss for Dense Object Detection." ICCV 2017.
  - https://arxiv.org/abs/1708.02002

**Feature Pyramid Network:**
- Lin, T. Y., et al. (2017). "Feature Pyramid Networks for Object Detection." CVPR 2017.
  - https://arxiv.org/abs/1612.03144

**Cl√°sicos:**
- Dalal, N., & Triggs, B. (2005). "Histograms of oriented gradients for human detection."
- Leutenegger, S., Chli, M., & Siegwart, R. Y. (2011). "BRISK: Binary robust invariant scalable keypoints."

## üöÄ Gu√≠a R√°pida: ¬øQu√© Modelo Usar?

### Usa **RetinaNet** si:
- ‚úÖ Necesitas la **mejor precisi√≥n** posible
- ‚úÖ Tienes GPU disponible
- ‚úÖ Puedes esperar ~2-3 horas de entrenamiento
- ‚úÖ Deployment en servidor o hardware moderno

### Usa **HOG + FC** si:
- ‚úÖ Necesitas entrenar **r√°pido** (~30 min)
- ‚úÖ Hardware limitado (CPU)
- ‚úÖ Precisi√≥n moderada es suficiente
- ‚úÖ Interpretabilidad de features

### Usa **BRISK + FC** si:
- ‚úÖ Necesitas el **modelo m√°s ligero**
- ‚úÖ Deployment en dispositivos IoT
- ‚úÖ Velocidad de inferencia cr√≠tica
- ‚úÖ Memoria muy limitada
