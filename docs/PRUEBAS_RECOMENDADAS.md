# üß™ Pruebas Adicionales Recomendadas

## ‚úÖ Pruebas Ya Completadas

### 1. Pruebas Unitarias
```bash
pytest tests/ -v --cov=src
```
- **Resultado**: 17/17 tests pasados (100%)
- **Cobertura**: 53%

### 2. Entrenamiento de Modelos
```bash
# HOG
python scripts/train.py --config configs/hog_config.yaml

# BRISK
python scripts/train.py --config configs/brisk_config.yaml
```
- **HOG**: 30% IoU, 31% precisi√≥n @0.5
- **BRISK**: 25% IoU, 21% precisi√≥n @0.5

### 3. Comparaci√≥n de Modelos
```bash
python compare_models.py
```
- **Resultado**: HOG gana en 4/7 m√©tricas
- **Archivos generados**: `model_comparison.png`

### 4. Benchmark de Velocidad
```bash
python benchmark_speed.py
```
- **HOG**: 111ms/imagen (~9 FPS)
- **BRISK**: 92ms/imagen (~11 FPS)
- **BRISK es 1.21x m√°s r√°pido**

### 5. An√°lisis de Errores
```bash
python analyze_errors.py
```
- **Genera**: 
  - `analysis_best_hog.png` - Mejores predicciones HOG
  - `analysis_worst_hog.png` - Peores predicciones HOG
  - `analysis_best_brisk.png` - Mejores predicciones BRISK
  - `analysis_worst_brisk.png` - Peores predicciones BRISK

---

## üî¥ PRIORIDAD ALTA - Hacer Ahora

### 1. Prueba con Im√°genes Nuevas (15 min)
**Objetivo**: Validar modelos con datos completamente nuevos

```bash
# Descargar im√°genes de test desde internet
mkdir -p data/test_external
# Coloca 5-10 im√°genes de autos con placas visibles

# Probar HOG
python scripts/inference.py \
    --model models/detection_hog_best.h5 \
    --image data/test_external/car1.jpg \
    --feature-type hog

# Probar BRISK
python scripts/inference.py \
    --model models/detection_brisk_best.h5 \
    --image data/test_external/car1.jpg \
    --feature-type brisk
```

**Qu√© buscar**:
- ¬øDetecta la placa correctamente?
- ¬øCu√°l modelo funciona mejor?
- ¬øHay casos donde ambos fallan?

---

### 2. Test de Robustez (20 min)
**Objetivo**: Ver c√≥mo responden los modelos a condiciones adversas

```bash
python test_robustness.py
```

**Genera visualizaciones** de c√≥mo cada modelo responde a:
-   Im√°genes oscuras/brillantes
-   Im√°genes con ruido
-   Im√°genes rotadas
-   Im√°genes con blur
-   Diferentes escalas

**Archivos generados**:
- `robustness_test_hog.png`
- `robustness_test_brisk.png`

---

### 3. An√°lisis de Velocidad Detallado (10 min)
**Objetivo**: Identificar cuellos de botella

Crea `profile_speed.py`:
```python
import time
import cv2
from src.features.hog import HOGFeatureExtractor
from src.features.brisk import BRISKFeatureExtractor

img = cv2.imread('data/raw/Cars0.png')

# HOG
hog = HOGFeatureExtractor()
times = []
for _ in range(100):
    start = time.time()
    features = hog.extract(img)
    times.append(time.time() - start)
print(f"HOG: {np.mean(times)*1000:.2f}ms ¬± {np.std(times)*1000:.2f}ms")

# BRISK
brisk = BRISKFeatureExtractor()
times = []
for _ in range(100):
    start = time.time()
    features = brisk.extract(img)
    times.append(time.time() - start)
print(f"BRISK: {np.mean(times)*1000:.2f}ms ¬± {np.std(times)*1000:.2f}ms")
```

---

### 4. Validaci√≥n Cruzada (30 min)
**Objetivo**: Asegurar que los modelos generalizan bien

Crea `cross_validation.py`:
```python
from sklearn.model_selection import KFold
import pickle
import numpy as np

# Cargar datos
with open('data/processed/detection_hog.pkl', 'rb') as f:
    data = pickle.load(f)

X = data['features']
y = data['bboxes']

# K-Fold Cross Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)
ious = []

for fold, (train_idx, val_idx) in enumerate(kf.split(X)):
    print(f"\nFold {fold+1}/5")
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]
    
    # Entrenar modelo
    # ... (usa el c√≥digo de train.py)
    
    # Evaluar
    # ... (calcula IoU promedio)
    
print(f"\nIoU promedio: {np.mean(ious):.3f} ¬± {np.std(ious):.3f}")
```

---

## üü° PRIORIDAD MEDIA - Siguiente Fase

### 5. Data Augmentation (1-2 d√≠as)
**Impacto esperado**: +10-15% en m√©tricas

Crea `augment_dataset.py`:
```python
import cv2
import numpy as np
from albumentations import (
    Compose, HorizontalFlip, RandomBrightnessContrast,
    Rotate, GaussianBlur, ShiftScaleRotate
)

# Definir augmentations
transform = Compose([
    HorizontalFlip(p=0.5),
    RandomBrightnessContrast(p=0.5),
    Rotate(limit=15, p=0.5),
    GaussianBlur(p=0.3),
    ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=10, p=0.5),
], bbox_params={'format': 'pascal_voc', 'label_fields': []})

# Aplicar a dataset
# Multiplicar dataset por 3-5x
```

Luego re-entrenar:
```bash
python scripts/prepare_dataset.py --augment
python scripts/train.py --config configs/hog_config.yaml --augmented
```

---

### 6. Ensemble de Modelos (4 horas)
**Impacto esperado**: +5-8% en m√©tricas

Crea `ensemble.py`:
```python
# Cargar ambos modelos
hog_model = load_model('models/detection_hog_best.h5', compile=False)
brisk_model = load_model('models/detection_brisk_best.h5', compile=False)

# Predicci√≥n combinada
def ensemble_predict(image):
    hog_features = extract_hog(image)
    brisk_features = extract_brisk(image)
    
    hog_pred = hog_model.predict(hog_features)
    brisk_pred = brisk_model.predict(brisk_features)
    
    # Promedio ponderado (HOG m√°s peso por ser m√°s preciso)
    final_pred = 0.6 * hog_pred + 0.4 * brisk_pred
    return final_pred
```

---

### 7. Optimizaci√≥n de Hiperpar√°metros (1 d√≠a)
**Impacto esperado**: +2-10% en m√©tricas

Crea `grid_search.py`:
```python
from sklearn.model_selection import ParameterGrid

# Definir grid
param_grid = {
    'learning_rate': [0.001, 0.0005, 0.0001],
    'batch_size': [16, 32, 64],
    'dropout': [0.3, 0.4, 0.5],
    'hidden_units': [512, 1024, 2048]
}

best_iou = 0
best_params = None

for params in ParameterGrid(param_grid):
    print(f"\nProbando: {params}")
    
    # Entrenar con estos par√°metros
    model = build_model(**params)
    history = train_model(model, X_train, y_train)
    
    # Evaluar
    iou = evaluate(model, X_val, y_val)
    
    if iou > best_iou:
        best_iou = iou
        best_params = params

print(f"\nMejores par√°metros: {best_params}")
print(f"IoU: {best_iou:.3f}")
```

---

### 8. Transfer Learning (2-3 d√≠as)
**Impacto esperado**: +10-20% en m√©tricas

```python
from tensorflow.keras.applications import ResNet50, MobileNetV2

# Usar features pre-entrenadas
base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')

def extract_resnet_features(image):
    # Preprocesar
    img = cv2.resize(image, (224, 224))
    img = preprocess_input(img)
    
    # Extraer features
    features = base_model.predict(np.expand_dims(img, 0))
    return features.flatten()
```

Luego entrenar FC network con estas features.

---

## üü¢ PRIORIDAD BAJA - Mejoras Futuras

### 9. Exportar para Producci√≥n
```bash
# TensorFlow Lite (m√≥viles)
python -c "
import tensorflow as tf
model = tf.keras.models.load_model('models/detection_hog_best.h5', compile=False)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open('models/detection_hog.tflite', 'wb').write(tflite_model)
"

# ONNX (interoperabilidad)
pip install tf2onnx
python -m tf2onnx.convert \
    --saved-model models/detection_hog_best.h5 \
    --output models/detection_hog.onnx
```

---

### 10. Crear API REST
```python
# app.py
from flask import Flask, request, jsonify
import cv2
import numpy as np

app = Flask(__name__)
model = load_model('models/detection_hog_best.h5', compile=False)

@app.route('/detect', methods=['POST'])
def detect():
    file = request.files['image']
    img = cv2.imdecode(np.frombuffer(file.read(), np.uint8), 1)
    
    features = extract_hog(img)
    bbox = model.predict(features)
    
    return jsonify({
        'bbox': bbox.tolist(),
        'confidence': float(calculate_confidence(bbox))
    })

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
```

```bash
python app.py
# Test: curl -F "image=@test.jpg" http://localhost:5000/detect
```

---

### 11. Pipeline de Video
```python
# video_detection.py
import cv2

cap = cv2.VideoCapture('video.mp4')
model = load_model('models/detection_brisk_best.h5', compile=False)  # BRISK es m√°s r√°pido

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # Detectar
    features = extract_brisk(frame)
    bbox = model.predict(features)
    
    # Dibujar
    draw_bbox(frame, bbox)
    cv2.imshow('Detection', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

## üìä Roadmap Sugerido (4 Semanas)

### Semana 1: Diagn√≥stico y Validaci√≥n
- [ ] An√°lisis de errores ‚úÖ (Completado)
- [ ] Test con im√°genes nuevas
- [ ] Test de robustez
- [ ] Validaci√≥n cruzada
- [ ] **Meta**: Entender limitaciones actuales

### Semana 2: Mejora de Datos
- [ ] Implementar data augmentation
- [ ] Re-entrenar ambos modelos
- [ ] Comparar resultados
- [ ] **Meta**: +10-15% en IoU

### Semana 3: Optimizaci√≥n
- [ ] Ensemble HOG + BRISK
- [ ] Grid search hiperpar√°metros
- [ ] Probar transfer learning
- [ ] **Meta**: +5-10% adicional en IoU

### Semana 4: Producci√≥n (Opcional)
- [ ] Exportar a TFLite/ONNX
- [ ] Crear API REST
- [ ] Pruebas de integraci√≥n
- [ ] **Meta**: Sistema deployable

---

## üéØ Objetivos de Mejora

| M√©trica | Actual | Objetivo | Estrategia |
|---------|--------|----------|------------|
| IoU Promedio | 30% | 45-55% | Data augmentation + Transfer learning |
| Precisi√≥n @0.5 | 31% | 50-70% | Ensemble + Optimizaci√≥n |
| Velocidad | 9 FPS | 15-30 FPS | Cuantizaci√≥n + Optimizaci√≥n |
| Tama√±o Modelo | 84 MB | <50 MB | Pruning + Cuantizaci√≥n |

---

## üí° Tips Importantes

1. **Siempre guarda tus experimentos**:
   ```bash
   mkdir experiments
   cp models/detection_hog_best.h5 experiments/baseline_hog.h5
   ```

2. **Documenta tus resultados**:
   ```bash
   echo "Experimento: Data Augmentation 3x" >> experiments/log.txt
   echo "IoU: 0.42" >> experiments/log.txt
   ```

3. **Usa versionado**:
   ```bash
   git add .
   git commit -m "feat: Add data augmentation, IoU improved to 0.42"
   ```

4. **Compara siempre con baseline**:
   - No borres modelos anteriores
   - Mant√©n scripts de evaluaci√≥n consistentes

---

## üöÄ Comando R√°pido para Empezar

```bash
# Test r√°pido de todo
cd /home/rickcontreras/proyectos/car-plate-classifier/fc-detection-project
source venv/bin/activate

# 1. An√°lisis de errores (ya hecho)
python analyze_errors.py

# 2. Descargar una imagen de prueba
wget -O data/test_car.jpg "https://example.com/car_with_plate.jpg"

# 3. Probar inferencia
python scripts/inference.py \
    --model models/detection_hog_best.h5 \
    --image data/test_car.jpg \
    --feature-type hog

# 4. Ver resultados
ls -lh *.png
```

---

## ‚ùì FAQ

**P: ¬øPor d√≥nde empiezo?**  
R: Empieza con las pruebas de PRIORIDAD ALTA. Son r√°pidas (15-30 min) y te dar√°n insights inmediatos.

**P: ¬øCu√°nto tiempo toma cada prueba?**  
- An√°lisis de errores: 5 min ‚úÖ
- Test con im√°genes nuevas: 15 min
- Test de robustez: 20 min
- Validaci√≥n cruzada: 30 min
- Data augmentation: 1-2 d√≠as
- Ensemble: 4 horas
- Transfer learning: 2-3 d√≠as

**P: ¬øQu√© prueba da m√°s mejora?**  
R: Por experiencia: Transfer Learning > Data Augmentation > Ensemble > Grid Search

**P: ¬øNecesito GPU?**  
R: No es obligatorio, pero ayuda mucho para transfer learning (10x m√°s r√°pido).

---

¬°√âxito con tus pruebas! üöÄ
